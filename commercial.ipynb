{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5806af12-4a09-48d9-a054-f2de5a8f27ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5452008-f61a-44e7-9b4a-1af84ca7bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('all.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51b9dbd-3701-4667-b932-cccf4ef2c05f",
   "metadata": {},
   "source": [
    "# Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1062986f-b7d0-4ded-a428-214abb0e1e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "f = \"all.xlsx\"\n",
    "ex = pd.ExcelFile(f)\n",
    "for shit in ex.sheet_names:\n",
    "    df = pd.read_excel(f,sheet_name=shit)\n",
    "    out = f\"{shit}.xlsx\"\n",
    "    df.to_excel(out,index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cb7f7c-cc19-4993-a809-c548eebf3e8a",
   "metadata": {},
   "source": [
    "# pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b754fe2b-6c92-4c54-83a0-d902de2893e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns  \n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import optuna\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # ignore notifications\n",
    "import sys\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b31a11-ccca-49ab-bec4-6ed88936f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('COM.xlsx')\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47006a3-6a20-4911-badd-3e72d70f59bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"Value counts for column: {col}\")\n",
    "    print(df[col].value_counts())\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0835084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3691814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47f24927-c8ce-41d0-bcb6-9b9583cf3c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1005 entries, 0 to 1004\n",
      "Data columns (total 25 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   listing litle                   1005 non-null   object \n",
      " 1   city                            1005 non-null   object \n",
      " 2   area                            1005 non-null   object \n",
      " 3   zone                            1005 non-null   object \n",
      " 4   location_hub                    1005 non-null   object \n",
      " 5   property_type                   1005 non-null   object \n",
      " 6   ownership                       1005 non-null   object \n",
      " 7   size_in_sqft                    1005 non-null   int64  \n",
      " 8   carpet_area_sqft                1005 non-null   object \n",
      " 9   private_washroom                1005 non-null   int64  \n",
      " 10  public_washroom                 1005 non-null   int64  \n",
      " 11  floor_no                        1005 non-null   object \n",
      " 12  total_floors                    1005 non-null   int64  \n",
      " 13  amenities_count                 1005 non-null   object \n",
      " 14  electric_charge_included        1005 non-null   object \n",
      " 15  water_charge_included           1005 non-null   object \n",
      " 16  property_age                    1005 non-null   object \n",
      " 17  possession_status               1005 non-null   object \n",
      " 18  posted_by                       1005 non-null   object \n",
      " 19  lock in period                  1005 non-null   object \n",
      " 20  expected rent increases yearly  1005 non-null   float64\n",
      " 21  negotiable                      1005 non-null   object \n",
      " 22  brokerage                       1005 non-null   object \n",
      " 23  security_deposite               1005 non-null   float64\n",
      " 24  rent_price                      1005 non-null   int64  \n",
      "dtypes: float64(2), int64(5), object(18)\n",
      "memory usage: 196.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e03545-e8e6-43c6-ba79-63777c9ca0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('location', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f3c859-328f-4329-9399-27ae3010910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(\" \", 0).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641bff61-5d94-4e4e-9ffa-2629b6d0a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = df.isnull().sum()\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd0490a-f0b1-4261-8150-1ff9f99deaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['floor_no'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e04d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['amenities_count'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86303b81-9713-48a1-a676-69bdb1a241e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def floor_to_int_list(floor_str):\n",
    "    floor_str = str(floor_str).lower()\n",
    "    floor_str = floor_str.replace('floor', '').replace('floors', '').replace(' ', '')\n",
    "    # Replace ground floor / GF with 0\n",
    "    floor_str = floor_str.replace('ground', '0').replace('gf', '0')\n",
    "    # Split multiple floors\n",
    "    parts = re.split(r'[,]', floor_str)\n",
    "    floor_numbers = []\n",
    "    for p in parts:\n",
    "        try:\n",
    "            floor_numbers.append(int(p))\n",
    "        except:\n",
    "            continue\n",
    "    # Return as comma-separated string\n",
    "    if floor_numbers:\n",
    "        return ','.join(map(str, sorted(floor_numbers)))\n",
    "    return None\n",
    "\n",
    "# Apply to your DataFrame\n",
    "df['floor_no'] = df['floor_no'].apply(floor_to_int_list)\n",
    "\n",
    "# Show result\n",
    "print(df[['floor_no']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66661f9-0414-4711-a5c4-1e4a26a1106a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df['total_floors'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b954c045-f111-418c-b6d9-0137e5bac232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def total_floors_to_int(floor_str):\n",
    "    try:\n",
    "        # Remove 'floors' or 'floor' and spaces, then convert to int\n",
    "        return int(str(floor_str).lower().replace('floors', '').replace('floor', '').strip())\n",
    "    except:\n",
    "        return None  # in case of unexpected value\n",
    "\n",
    "# Apply to DataFrame\n",
    "df['total_floors'] = df['total_floors'].apply(total_floors_to_int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c1c87c-4f3a-47a7-b792-f05b6c4d2018",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['total_floors'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a09b2a4-8bb3-462b-bf8a-75e510cbe14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['size_in_sqft'].value_counts())\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4107daf4-e3e9-4069-a2ad-9e3b896c7ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to convert size to integer\n",
    "def size_to_int(size_str):\n",
    "    try:\n",
    "        # Remove 'sqft' or 'sq.ft' and spaces, then convert to int\n",
    "        return int(str(size_str).lower().replace('sqft','').replace('sq.ft','').strip())\n",
    "    except:\n",
    "        return None  # in case of unexpected value\n",
    "\n",
    "# Apply to DataFrame\n",
    "df['size_in_sqft_int'] = df['size_in_sqft'].apply(size_to_int)\n",
    "\n",
    "# Check result\n",
    "print(df[['size_in_sqft', 'size_in_sqft_int']].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b502f609-899b-4f9a-899a-5ac386aaa236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['size_in_sqft'] = df['size_in_sqft_int']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730ed430-5a4b-4aeb-b202-ad5dcd655820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to convert size to integer\n",
    "def size_to_int(size_str):\n",
    "    try:\n",
    "        # Remove 'sqft' or 'sq.ft' and spaces, then convert to int\n",
    "        return int(str(size_str).lower().replace('sqft','').replace('sq.ft','').strip())\n",
    "    except:\n",
    "        return None  # in case of unexpected value\n",
    "\n",
    "# Apply to DataFrame\n",
    "df['size_in_sqft_int'] = df['size_in_sqft'].apply(size_to_int)\n",
    "\n",
    "# Check result\n",
    "print(df[['size_in_sqft', 'size_in_sqft_int']].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a57d662-c4d8-4878-8250-9671ff5a148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('size_in_sqft_int', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894e9442-63da-4499-adf5-e9985cbb05d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to convert size to integer\n",
    "def size_to_int(size_str):\n",
    "    try:\n",
    "        # Remove 'sqft' or 'sq.ft' and spaces, then convert to int\n",
    "        return int(str(size_str).lower().replace('sqft','').replace('sq.ft','').strip())\n",
    "    except:\n",
    "        return None  # in case of unexpected value\n",
    "\n",
    "# Apply to DataFrame\n",
    "df['size_in_sqft_int'] = df['size_in_sqft'].apply(size_to_int)\n",
    "\n",
    "# Check result\n",
    "print(df[['size_in_sqft', 'size_in_sqft_int']].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6a5d7f-1d50-46ad-9a6f-1bca45daa58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bcdcfb-57f5-4495-9006-06e256efde61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e8d3af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80920900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb8e5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5679378f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9be434e-cd8e-44cd-a467-f5ed1e4c935b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13069384-ca38-4df7-bf0f-e06043304a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Feature Engineering: One-Hot Encoding Categorical Features ---\")\n",
    "categorical_features = ['City','Area', 'Zone', 'Frurnishing_Status', 'Brokerage', 'Maintenance_Charge', 'Recomened for', 'Muncipla Water Or Bore Water', 'Type of Society', 'Room', 'Type']\n",
    "for feature in categorical_features:\n",
    "    if feature in df.columns:\n",
    "        df = pd.get_dummies(df, columns=[feature], drop_first=True)\n",
    "        print(f\"One-hot encoded '{feature}'.\")\n",
    "    else:\n",
    "        print(f\"Warning: Categorical feature '{feature}' not found in DataFrame for encoding.\")\n",
    "\n",
    "\n",
    "# Transform 'Rent' using natural logarithm to reduce skewness\n",
    "print(\"--- Feature Engineering: Log Transformation of 'Rent' ---\")\n",
    "# Add a small constant to Rent to avoid log(0) if any rent value is 0\n",
    "df['Rent_Price'] = np.log1p(df['Rent_Price']) # Using log1p which is log(1+x)\n",
    "print(\"Applied log transformation to 'Rent' column.\")\n",
    "\n",
    "print(\"\\n--- DataFrame after Feature Engineering ---\")\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66fb8bc-69f2-4b70-ab48-5709fe3d2ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = df.drop('Rent_Price', axis=1)\n",
    "y = df['Rent_Price']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"\\nData split into training (80%) and testing (20%) sets.\")\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ff4a7b-b8fd-4717-bc02-b76dff65a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['Size_In_Sqft', 'Carpet_Area_Sqft', 'Bedrooms', 'Bathrooms', 'Balcony',\n",
    "'Number_Of_Amenities', 'Floor_No', 'Total_floors_In_Building',\n",
    "'Road_Connectivity', 'gated_community', 'gym', 'intercom', 'lift', 'pet_allowed', 'pool',\n",
    "'security', 'water_supply', 'wifi', 'gas_pipeline', 'sports_facility', 'kids_area',\n",
    "'power_backup', 'Garden', 'Fire_Support', 'Parking', 'ATM_Near_me', 'Airport_Near_me',\n",
    "'Bus_Stop__Near_me', 'Hospital_Near_me', 'Mall_Near_me', 'Market_Near_me',\n",
    "'Metro_Station_Near_me', 'Park_Near_me', 'School_Near_me', 'Property_Age']\n",
    "# Filter numerical_cols to only include columns actually present in X_train\n",
    "numerical_cols_present = [col for col in numerical_cols if col in X_train.columns]\n",
    "\n",
    "# 1. Replace empty strings with NaN\n",
    "X_train = X_train.replace(r'^\\s*$', np.nan, regex=True)\n",
    "X_test = X_test.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "# 2. Convert all numeric columns to float\n",
    "X_train[numerical_cols_present] = X_train[numerical_cols_present].apply(pd.to_numeric, errors='coerce')\n",
    "X_test[numerical_cols_present] = X_test[numerical_cols_present].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 3. Fill NaN with median for each column\n",
    "for col in numerical_cols_present:\n",
    "    median_val = X_train[col].median()\n",
    "    X_train[col].fillna(median_val, inplace=True)\n",
    "    X_test[col].fillna(median_val, inplace=True)\n",
    "\n",
    "# 4. Scale the numeric columns\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_cols_present] = scaler.fit_transform(X_train[numerical_cols_present])\n",
    "X_test[numerical_cols_present] = scaler.transform(X_test[numerical_cols_present])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67159c07-d2ad-4298-b069-68f0acdf35f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed94647-effa-4b8b-b46c-2d3aa776a018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1656e289-64b6-411d-966c-500a0619f3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711be3b3-3407-46ee-8eae-1d06dab5efea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03cd4aa-b963-4485-8e88-38fb2996b999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b44210-81a5-4389-8a4d-36010456ffd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597fd008-ca24-4c37-812d-4c18559564df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7654d19f-7356-47f9-8609-b90651508222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d1c2fa-b876-4dc3-bd4f-88ecd76f9f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "print(\"\\n--- Model Training: Random Forest Regressor ---\")\n",
    "# Initialize and train the Random Forest Regressor model\n",
    "# Using parameters that generally give good results, but further tuning can be done.\n",
    "rf_model = RandomForestRegressor(n_estimators=450,n_jobs=-1,random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"Random Forest Regressor model trained.\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "\n",
    "print(f\"\\n--- Model Evaluation (Random Forest) ---\")\n",
    "print(f\"R-squared (R^2) Score: {r2_rf:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_rf:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a179a656-086b-47b3-8db4-a957d73e5ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# If X_train is a DataFrame\n",
    "feature_names = X_train.columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert to percentage\n",
    "importances_percentage = 100 * importances / importances.sum()\n",
    "\n",
    "# Create DataFrame of feature importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance (%)': importances_percentage\n",
    "}).sort_values(by='Importance (%)', ascending=False)\n",
    "\n",
    "print(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcaba45-c9d6-41b9-8524-e1dd32b565e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df.to_excel(\"predicted.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb1cc9-1385-478b-9ac6-6b6d1012e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Saving the trained model and scaler ---\n",
    "import joblib\n",
    "print(\"\\n--- Saving Model and Scaler ---\")\n",
    "try:\n",
    "    joblib.dump(rf_model, 'm3.pkl')\n",
    "    joblib.dump(scaler, 's3.pkl')\n",
    "    joblib.dump(X.columns.tolist(), 'f3.pkl') # Save feature names for consistency\n",
    "    print(\"Model, scaler, and feature names saved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving model/scaler: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b1e380-e47d-4d29-b4dd-a73d99510e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save with compression\n",
    "joblib.dump(rf_model, \"m.pkl\", compress=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64db4f29-e8c8-404a-8b90-6708a0653fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
